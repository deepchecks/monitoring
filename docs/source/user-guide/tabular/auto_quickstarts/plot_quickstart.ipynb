{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Quickstart - Get Deepchecks Monitoring Up and Running\n\nThis quickstart is the perfect starting point for monitoring your tabular model using Deepchecks Monitoring. We'll\nquickly walk you through setting up a model to represent your task in the system, uploading data, setting the\ncomputed checks and alerts in the system and seeing some results for your effort. We'll be using the\n[Airbnb rent regression dataset](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data)_, in which\nthe rent of the Airbnb unit is predicted from a set of features describing the rental unit.\n\n```bash\n# Before we start, if you don't have deepchecks-client installed yet, run:\nimport sys\n!{sys.executable} -m pip install -U deepchecks-client\n\n# or install using pip from your python environment\n```\n## Creating a New Model Version\n\nOur first step is to create a new model version in the system. A model in Deepchecks Monitoring\nrepresents an ML pipeline performing a single task in production through time,\nwhere the model's versions and the structure of the data may change over time.\nOur terminology to refer to a specific version within a model is \"model version\".\n\nIn order to create a version we must specify the feature schema of the version, including the names and\ntypes of the features. It is also highly recommended to provide the feature importance of these features,\nwhich is used by the system to prioritize features in various calculations and displays.\n\nThe easiest way to create a model version, which is demonstrated\nhere, requires a :doc:`Dataset <deepchecks:user-guide/tabular/dataset_object>` object\ncontaining the reference data for the version. Reference data is a dataset to which we wish to compare\nour production data stream. Typically, this will be the dataset on which the model was trained.\nProviding reference data is optional yet many important :doc:`checks <deepchecks:user-guide/general/deepchecks_hierarchy>`\nsuch as :doc:`Train Test Feature Drift (Tabular Version) <deepchecks:checks_gallery/tabular/train_test_validation/plot_train_test_feature_drift>`\ncannot run without it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the Reference Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.regression.airbnb import load_data, \\\n    load_pre_calculated_prediction, load_pre_calculated_feature_importance\n\nref_dataset, _ = load_data(data_format='Dataset')\nref_predictions, _ = load_pre_calculated_prediction()\nfeature_importance = load_pre_calculated_feature_importance()\nfeature_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating the Data Schema\nSchema file contains the description of the data (features and non features) associated with a model version.\n**It is highly recommended to review the created schema file before moving forward to creating the model version.**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks_client import DeepchecksClient, create_schema, read_schema\n\nschema_file_path = 'schema_file.yaml'\ncreate_schema(dataset=ref_dataset, schema_output_file=schema_file_path)\nread_schema(schema_file_path)\n# Note: for conveniently changing the auto-inferred schema it's recommended to edit the textual file with an app of your choice.\n# After editing, you can use the `read_schema` function to verify the validity of the syntax in your updated schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a model version\nIn order to create a model version we must first create an organization in the\n[deepchecks system](https://app.deepchecks.com/) and generate a personal\nAPI token using the application's dashboard.\n\n<img src=\"file://_static/images/quickstart/get_api_token.png\" width=\"600\">\n\nUsing the API token we can now create a new model version and upload the reference data.\nFor classification tasks, also predicted probabilities can be sent\nthrough the `reference_proba` argument, enabling computation of probability\nbased metrics such as AUC, log_loss, brier scorer and more.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nos.environ['DEEPCHECKS_API_HOST'] = 'https://app.deepchecks.com'\n# note to put the API token in your environment variables. Or alternatively (less recommended):\n# os.environ['DEEPCHECKS_API_TOKEN'] = 'uncomment-this-line-and-insert-your-api-token-here'\ndc_client = DeepchecksClient(host=os.getenv('DEEPCHECKS_API_HOST'), token=os.getenv('DEEPCHECKS_API_TOKEN'))\nmodel_version = dc_client.create_tabular_model_version(model_name='Airbnb', version_name='ver_1',\n                                                       schema_file=schema_file_path,\n                                                       feature_importance=feature_importance.to_dict(),\n                                                       reference_dataset=ref_dataset,\n                                                       reference_predictions=ref_predictions,\n                                                       task_type='regression')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uploading Production Data\n\nNo matter what else you'll be doing with Deepchecks Monitoring, it will start by uploading some production data that\nyou want monitored. In this example we will upload as a batch the data and predictions stored for the month\nof August 2022 then update the labels for some of the samples we uploaded.\n\n### Uploading Data and Predictions\nSame as with the reference data, for classification tasks also predicted probabilities can be sent\nenabling computation of probability based metrics such as AUC, log_loss, brier scorer and more.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ntimestamp, label_col = 'datestamp', 'price'\n_, prod_data = load_data(data_format='DataFrame')\n_, prod_predictions = load_pre_calculated_prediction()\nprod_predictions = pd.Series(prod_predictions, index=prod_data.index)\n# If labels arrive along with the data it is possible to upload them directly via the labels param.\nmodel_version.log_batch(data=prod_data.drop([timestamp, label_col], axis=1),\n                        timestamps=prod_data[timestamp], predictions=prod_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Updating the Labels\nIn many real world scenarios, the labels of the data are only available at a later time. We can update them\nin hindsight using the global sample ids.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_version.update_batch(samples_to_update=prod_data.index, labels=prod_data[label_col])\n\n# We can verify that status of the process that is running in the background by checking\n# the amount of samples that have been processed and uploaded by the system, using:\n# model_version.time_window_statistics(min(prod_data[timestamp]), max(prod_data[timestamp]))\n# upon completion, the statistics should equal the total number of samples sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Dashboard Screen\nAfter creating the model version and uploading the data, we can now see the monitors within the\n[application dashboard](https://app.deepchecks.com/).\nThe monitors below are generated by default when a new model is created, all versions of the same model are tracked\nwithin the same monitor.\n\n<img src=\"file://_static/images/quickstart/dashboard_w_defaults.png\" width=\"600\">\n\nIf we wish to remove the model do free up space for new models we can do it in the following way:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# CAUTION: This will delete the model, all model versions, and all associated datasets.\ndc_client.delete_model('Airbnb')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}